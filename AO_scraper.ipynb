{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atlas Obscura scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import pickle\n",
    "import os\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getting links to crawl through"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the following cell is marked as \"raw\" so it won't run with the notebook, since it's already scraped. To \"turn it back on\", select and press **Y**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# download the main page\n",
    "mainpage = requests.get(\"https://www.atlasobscura.com/destinations\")\n",
    "\n",
    "# use beautifulsoup to get all the links for the pages with lists of activities\n",
    "mainpagebs = bs(mainpage.text, 'html.parser')    \n",
    "mplinks = mainpagebs.find_all(href=re.compile(\"/things-to-do/\"))\n",
    "\n",
    "# turn the beautifulsoup result into a list of links\n",
    "mplinklist = [x.get('href') for x in mplinks]\n",
    "\n",
    "#remove urls for event pages, append \"/places\"\n",
    "eventlinks = [i for i, s in enumerate(mplinklist) if 'event' in s]\n",
    "mainpagefinal = [x for y, x in enumerate(mplinklist) if y not in eventlinks]\n",
    "mainpagefinal = [x +'/places' for x in mainpagefinal]\n",
    "\n",
    "# save links\n",
    "with open('listoflocations', 'wb') as outfile:\n",
    "    pickle.dump(mainpagefinal, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/things-to-do/australia/places', '/things-to-do/canada/places', '/things-to-do/china/places']\n"
     ]
    }
   ],
   "source": [
    "# to open them later:\n",
    "with open('data/listoflocations', 'rb') as infile:\n",
    "    listcopy = pickle.load(infile)\n",
    "    \n",
    "print(listcopy[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### crawling through each location page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now that we have all the links for locations directories from Atlas Obscura, we can crawl those to get the links for each individual location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to crawl a location and get links to destinations\n",
    "def crawlao(aourl):\n",
    "    links = []\n",
    "    pagecount = 1\n",
    "    hitend = False\n",
    "    while hitend is False:\n",
    "        page = requests.get('https://www.atlasobscura.com' + aourl + '?page=' + str(pagecount))\n",
    "        bspage = bs(page.text, 'html.parser')\n",
    "        bslocs = bspage.find_all('a', 'content-card content-card-place')\n",
    "        linktmp = [x.get('href') for x in bslocs]\n",
    "        if len(linktmp) < 1:\n",
    "            hitend = True\n",
    "            print('we have reached the end')\n",
    "        else:\n",
    "            links += linktmp\n",
    "            print(str(pagecount), sep=' ', end=' ', flush=True)\n",
    "            #print('scraping page ' + str(pagecount) + ' of ' + aourl)\n",
    "            pagecount += 1\n",
    "    return links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we're turning the cell \"off\" by turning it into raw - we don't want to scrape all those pages multiple times!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# save it in a dictionary\n",
    "AOLINKS = {}\n",
    "\n",
    "for country in mainpagefinal:\n",
    "    # get country name and print initial message\n",
    "    place = re.sub('(/things-to-do/)|(/places)', '', country)\n",
    "    print('BEGGINING TO SCRAPE ' + place)\n",
    "    # do the thing\n",
    "    links = crawlao(country)\n",
    "    #add to dictionary\n",
    "    AOLINKS[place] = links\n",
    "    #save to file\n",
    "    with open('masterlinks', 'wb') as outfile:\n",
    "        pickle.dump(AOLINKS, outfile)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ghana': ['/places/kakum-canopy-walk',\n",
       "  '/places/sacred-crocodile-ponds-of-paga',\n",
       "  '/places/mole-national-park',\n",
       "  '/places/cape-coast-castle',\n",
       "  '/places/tengzug-shrine',\n",
       "  '/places/larabanga-mosque',\n",
       "  '/places/ga-adangbe-caskets',\n",
       "  '/places/agbogbloshie'],\n",
       " 'kenya': ['/places/gedi-ruins',\n",
       "  '/places/giraffe-manor',\n",
       "  '/places/giraffe-centre',\n",
       "  '/places/kitum-cave',\n",
       "  '/places/marafa-depression',\n",
       "  '/places/mara-river-crossing',\n",
       "  '/places/carnivore-restaurant-nairobi',\n",
       "  '/places/kitengela',\n",
       "  '/places/donkeys-of-lamu-island',\n",
       "  '/places/nairobi-railway-museum',\n",
       "  '/places/george-adamson-s-grave',\n",
       "  '/places/iten-home-of-champions']}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load saved list:\n",
    "with open('data/masterlinks', 'rb') as infile:\n",
    "    aolinks = pickle.load(infile)\n",
    "    \n",
    "aolinks.keys()\n",
    "\n",
    "# example way to subset the links by country, so we can quickly see what the data structure looks like\n",
    "sublinks = {k: aolinks[k] for k in ('ghana', 'kenya')}\n",
    "sublinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16491"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the total number of links I'll have to scrape\n",
    "# len(value) for key, value in d.items()\n",
    "sum([len(x) for _,x in aolinks.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scrape all the links!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the directory where we'll save the scraped pages\n",
    "\n",
    "if os.path.exists('jsons') == False: os.makedirs('jsons')\n",
    "\n",
    "'''errors with scraping are pretty common,\n",
    "this is a simple checkpointing in case it gets messed up\n",
    "'''\n",
    "\n",
    "if os.path.isfile('data/AOmasterdata'):\n",
    "    AOdata = pickle.load(open('data/AOmasterdata', 'rb'))  \n",
    "else:\n",
    "    AOdata = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 170 µs, sys: 1 µs, total: 171 µs\n",
      "Wall time: 175 µs\n"
     ]
    }
   ],
   "source": [
    "# set scraping session parameters\n",
    "session = requests.Session()\n",
    "retry = Retry(connect=3, backoff_factor=0.5)\n",
    "adapter = HTTPAdapter(max_retries=retry)\n",
    "session.mount('http://', adapter)\n",
    "session.mount('https://', adapter)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "%%time\n",
    "\n",
    "# Loop to crawl through the Atlas Obscura pages\n",
    "\n",
    "for key in AOLINKS:\n",
    "    print('now scraping ' + key +\":\")\n",
    "    pgnum = 1\n",
    "    for value in AOLINKS[key]:\n",
    "        filename = 'jsons/'+ re.sub('/places/', '', value) + \".html\"\n",
    "        \n",
    "        pgnum += 1\n",
    "        \n",
    "        # stop loop if file exists\n",
    "        #if os.path.exists(filename):\n",
    "        #    continue   \n",
    "        \n",
    "        # page request, beautifulsoup\n",
    "        page = session.get(\"https://www.atlasobscura.com\" + value)\n",
    "        bspage = bs(page.text, \"html.parser\")\n",
    "        \n",
    "        # save file\n",
    "        with open(filename, \"w\") as file:\n",
    "            file.write(str(bspage))\n",
    "        \n",
    "        # get JSON info\n",
    "        summaryinfo = bspage.find('script', string=re.compile('AtlasObscura.current_place')).text\n",
    "\n",
    "        # remove trailing garbage\n",
    "        summaryinfo = re.sub('(\\s+)|(;)|(AtlasObscura.current_place = )', ' ', summaryinfo)\n",
    "        json_summaryinfo = json.loads(summaryinfo)\n",
    "\n",
    "        summary_subset = {k: json_summaryinfo[k] for k in \n",
    "                          ('id', 'title', 'subtitle', 'city', 'country', 'location', 'url', 'physical_status',  \n",
    "                           'coordinates')}\n",
    "\n",
    "        summary_subset.update({'lat' : summary_subset['coordinates']['lat']})\n",
    "        summary_subset.update({'lng' : summary_subset['coordinates']['lng']})\n",
    "\n",
    "        del(summary_subset['coordinates'])\n",
    "\n",
    "        # get JSON keywords\n",
    "        kw = bspage.find('script', type=\"application/ld+json\").text\n",
    "        kw = json.loads(kw, strict = False)\n",
    "\n",
    "        summary_subset.update({'keywords': \",\".join(kw['keywords'])})\n",
    "\n",
    "        # Extract the description\n",
    "        descript = ''.join([x.text.replace(u'\\xa0', u' ') for x in bspage.find(id='place-body').find_all('p')])\n",
    "        summary_subset.update({'description': descript})\n",
    "        \n",
    "        # add to DataFrame\n",
    "        AOdata = AOdata.append(pd.DataFrame(summary_subset, index=[0]))\n",
    "\n",
    "        # loop tracking\n",
    "        if pgnum % 10 == 0:\n",
    "            print(str(pgnum) , sep=' ', end=' ', flush=True)\n",
    "        #   time.sleep(1)\n",
    "        #if pgnum % 100 == 0:\n",
    "        #   time.sleep(5)\n",
    "\n",
    "    print('done, pickling...')\n",
    "    #time.sleep(5)\n",
    "    \n",
    "    with open('data/AOmasterdata', 'wb') as outfile:\n",
    "        pickle.dump(AOdata, outfile)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do some cleaning up due to the multiple merging of tables..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "AOdata.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicated ids: 2118\n",
      "duplicated titles: 2141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nThere are several entries with duplicated titles that are NOT duplicated;\\nfor example, there are muliple \"Hidden Beach\" in different cities.\\nImportant to subset by \"id\", not \"title\".\\n'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('duplicated ids: ' + str(sum(AOdata.duplicated('id'))))\n",
    "print('duplicated titles: ' + str(sum(AOdata.duplicated('title'))))\n",
    "\n",
    "'''\n",
    "There are several entries with duplicated titles that are NOT duplicated;\n",
    "for example, there are muliple \"Hidden Beach\" in different cities.\n",
    "Important to subset by \"id\", not \"title\".\n",
    "'''\n",
    "\n",
    "#AOdata[AOdata['title'] == 'Soumaya Museum' ]\n",
    "\n",
    "# dupnamesnotid = list(AOdata[AOdata.duplicated('title') & ~AOdata.duplicated('id') ]['title'])\n",
    "\n",
    "# for i in dupnamesnotid:\n",
    "#     print(AOdata[AOdata['title'] == i])\n",
    "\n",
    "#AOdata[AOdata['title'] == 'Titanic Memorial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw table: 16233\n",
      "clean table: 14115\n"
     ]
    }
   ],
   "source": [
    "AOdata_clean = AOdata.drop_duplicates('id').reset_index(drop=True)\n",
    "\n",
    "AOdata_clean['keywords'] = AOdata_clean['keywords'].replace('(,section-Atlas)|(section-Atlas)', '', regex=True)\n",
    "\n",
    "print(\"raw table: \" + str(len(AOdata)))\n",
    "print(\"clean table: \" + str(len(AOdata_clean)))\n",
    "\n",
    "# with open('AOmasterdata', 'wb') as outfile:\n",
    "#     pickle.dump(AOdata_clean, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/AOmasterdata-full-week3', 'wb') as outfile:\n",
    "     pickle.dump(AOdata, outfile)\n",
    "\n",
    "with open('data/AOmasterdata-nodup-week3', 'wb') as outfile:\n",
    "     pickle.dump(AOdata_clean, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   keyword  count\n",
      "0   architectural oddities   1407\n",
      "1                  museums   1385\n",
      "2  museums and collections   1201\n",
      "3                      art    915\n",
      "4                  history    912\n"
     ]
    }
   ],
   "source": [
    "megastring = \",\".join(AOdata_clean['keywords'].tolist())\n",
    "\n",
    "keys = megastring.split(\",\")\n",
    "\n",
    "keystable = pd.DataFrame(Counter(keys), index=['count']).T.reset_index().rename(columns={'index':'keyword'})\n",
    "\n",
    "keystable = keystable.sort_values(by='count', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(keystable.head())\n",
    "\n",
    "keystable.to_csv('data/keywords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>location</th>\n",
       "      <th>url</th>\n",
       "      <th>physical_status</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>keywords</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6282</th>\n",
       "      <td>7898</td>\n",
       "      <td>Museum de Gevangenpoort (The Prison Gate Museum)</td>\n",
       "      <td>A seven-century-old jail tells a not-so-pleasa...</td>\n",
       "      <td>The Hague</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>The Hague, Netherlands</td>\n",
       "      <td>https://www.atlasobscura.com/places/the-prison...</td>\n",
       "      <td></td>\n",
       "      <td>52.079508</td>\n",
       "      <td>4.310292</td>\n",
       "      <td>prisons,museums,museums and collections,tortur...</td>\n",
       "      <td>Ironically (or appropriately) situated in the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                             title  \\\n",
       "6282  7898  Museum de Gevangenpoort (The Prison Gate Museum)   \n",
       "\n",
       "                                               subtitle       city  \\\n",
       "6282  A seven-century-old jail tells a not-so-pleasa...  The Hague   \n",
       "\n",
       "          country                location  \\\n",
       "6282  Netherlands  The Hague, Netherlands   \n",
       "\n",
       "                                                    url physical_status  \\\n",
       "6282  https://www.atlasobscura.com/places/the-prison...                   \n",
       "\n",
       "            lat       lng                                           keywords  \\\n",
       "6282  52.079508  4.310292  prisons,museums,museums and collections,tortur...   \n",
       "\n",
       "                                            description  \n",
       "6282  Ironically (or appropriately) situated in the ...  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AOdata_clean[AOdata_clean['id'] == 7898]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull JPG URL from files\n",
    "\n",
    "img_url = []\n",
    "\n",
    "aofile = [x for x in os.listdir('jsons') if x.endswith(\".html\")]\n",
    "\n",
    "\n",
    "for entry in aofile:\n",
    "    with open('jsons/'+entry, 'r') as infile:\n",
    "        aohtml_pre = infile.read()\n",
    "\n",
    "    aohtml = bs(aohtml_pre, 'html.parser')\n",
    "\n",
    "    # get JSON info\n",
    "    summaryinfo = aohtml.find('script', string=re.compile('AtlasObscura.current_place')).text\n",
    "    # remove trailing garbage\n",
    "    summaryinfo = re.sub('(\\s+)|(;)|(AtlasObscura.current_place = )', ' ', summaryinfo)\n",
    "    json_summaryinfo = json.loads(summaryinfo)\n",
    "\n",
    "    img_url.append({'id': json_summaryinfo['id'], \n",
    "              'imgurl': aohtml.find('a',{\"class\": \"js-trigger-lightbox gallery-image-container\"})['data-lightbox-src']})\n",
    "    \n",
    "    # save file with the id as its new name\n",
    "    with open('jsons_byid/'+str(json_summaryinfo['id'])+'.html', \"w\") as file:\n",
    "        file.write(str(aohtml_pre))\n",
    "\n",
    "img_url_df = pd.DataFrame(img_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if all values are found in the main dataset\n",
    "set(img_url_df['id']).issubset(AOdata_clean['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_merge\n",
      "left_only         0\n",
      "right_only        0\n",
      "both          14115\n",
      "Name: id, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>location</th>\n",
       "      <th>url</th>\n",
       "      <th>physical_status</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>keywords</th>\n",
       "      <th>description</th>\n",
       "      <th>imgurl_x</th>\n",
       "      <th>imgurl_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5561</td>\n",
       "      <td>Lake Hillier</td>\n",
       "      <td>An Australian lake whose pink hue defies scien...</td>\n",
       "      <td></td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>https://www.atlasobscura.com/places/lake-hillier</td>\n",
       "      <td></td>\n",
       "      <td>-34.094179</td>\n",
       "      <td>123.203276</td>\n",
       "      <td>wonders of salt,natural wonders,watery wonders</td>\n",
       "      <td>From a distance, Lake Hillier of Australia’s R...</td>\n",
       "      <td>https://assets.atlasobscura.com/media/W1siZiIs...</td>\n",
       "      <td>https://assets.atlasobscura.com/media/W1siZiIs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4290</td>\n",
       "      <td>Gippsland Lakes Bioluminescence</td>\n",
       "      <td>Australian Lake set aglow by Noctiluca Scintil...</td>\n",
       "      <td>Raymond Island</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Raymond Island, Australia</td>\n",
       "      <td>https://www.atlasobscura.com/places/lake-gipps...</td>\n",
       "      <td></td>\n",
       "      <td>-37.922431</td>\n",
       "      <td>147.791342</td>\n",
       "      <td>watery wonders,bioluminescence</td>\n",
       "      <td>The conditions were rare, and they were perfec...</td>\n",
       "      <td>https://assets.atlasobscura.com/media/W1siZiIs...</td>\n",
       "      <td>https://assets.atlasobscura.com/media/W1siZiIs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>596</td>\n",
       "      <td>The Haunted Bookshop</td>\n",
       "      <td>Occult books, Tarot, Oddities.</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Melbourne, Australia</td>\n",
       "      <td>https://www.atlasobscura.com/places/haunted-bo...</td>\n",
       "      <td></td>\n",
       "      <td>-37.815472</td>\n",
       "      <td>144.961689</td>\n",
       "      <td>repositories of knowledge,occult,bookstores</td>\n",
       "      <td>The creepy Haunted Bookshop in Melbourne is lo...</td>\n",
       "      <td>https://assets.atlasobscura.com/media/W1siZiIs...</td>\n",
       "      <td>https://assets.atlasobscura.com/media/W1siZiIs...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                            title  \\\n",
       "0  5561                     Lake Hillier   \n",
       "1  4290  Gippsland Lakes Bioluminescence   \n",
       "2   596             The Haunted Bookshop   \n",
       "\n",
       "                                            subtitle            city  \\\n",
       "0  An Australian lake whose pink hue defies scien...                   \n",
       "1  Australian Lake set aglow by Noctiluca Scintil...  Raymond Island   \n",
       "2                     Occult books, Tarot, Oddities.       Melbourne   \n",
       "\n",
       "     country                   location  \\\n",
       "0  Australia                  Australia   \n",
       "1  Australia  Raymond Island, Australia   \n",
       "2  Australia       Melbourne, Australia   \n",
       "\n",
       "                                                 url physical_status  \\\n",
       "0   https://www.atlasobscura.com/places/lake-hillier                   \n",
       "1  https://www.atlasobscura.com/places/lake-gipps...                   \n",
       "2  https://www.atlasobscura.com/places/haunted-bo...                   \n",
       "\n",
       "         lat         lng                                        keywords  \\\n",
       "0 -34.094179  123.203276  wonders of salt,natural wonders,watery wonders   \n",
       "1 -37.922431  147.791342                  watery wonders,bioluminescence   \n",
       "2 -37.815472  144.961689     repositories of knowledge,occult,bookstores   \n",
       "\n",
       "                                         description  \\\n",
       "0  From a distance, Lake Hillier of Australia’s R...   \n",
       "1  The conditions were rare, and they were perfec...   \n",
       "2  The creepy Haunted Bookshop in Melbourne is lo...   \n",
       "\n",
       "                                            imgurl_x  \\\n",
       "0  https://assets.atlasobscura.com/media/W1siZiIs...   \n",
       "1  https://assets.atlasobscura.com/media/W1siZiIs...   \n",
       "2  https://assets.atlasobscura.com/media/W1siZiIs...   \n",
       "\n",
       "                                            imgurl_y  \n",
       "0  https://assets.atlasobscura.com/media/W1siZiIs...  \n",
       "1  https://assets.atlasobscura.com/media/W1siZiIs...  \n",
       "2  https://assets.atlasobscura.com/media/W1siZiIs...  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making sure the merge is successful:\n",
    "print(pd.merge(AOdata_clean, img_url_df, on='id', how='left', indicator=True).groupby('_merge').count()['id'])\n",
    "\n",
    "AOdata_clean = pd.merge(AOdata_clean, img_url_df, on='id', how='left')\n",
    "\n",
    "AOdata_clean.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('data/AOmasterdata-nodup-week3', 'wb') as outfile:\n",
    "     pickle.dump(AOdata_clean, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
